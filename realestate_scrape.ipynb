{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## House listing web-scraper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Main source:** https://towardsdatascience.com/looking-for-a-house-build-a-web-scraper-to-help-you-5ab25badc83e?gi=9fdc49d7312b\n",
    "\n",
    "Scraped webpage name and URL is not included"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from requests import get\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import re\n",
    "import time as t\n",
    "from numpy import random\n",
    "import unicodedata\n",
    "import numpy as np\n",
    "from datetime import date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flat database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flat_prices(city_list):\n",
    "    \n",
    "    FlatDataAll = pd.DataFrame(columns = ['ár (M Ft)', 'nm ár', 'méret', 'cím', 'szobák száma', 'település', 'hirdetés link'])\n",
    "    \n",
    "    #pages = list(range(1,2))\n",
    "    url_fix = \"Fix part of the URL\"\n",
    "    \n",
    "    '''\n",
    "    all_obs: contains the number of total flat listings in Hungary, this is neccesary to troubleshoot against\n",
    "    non-existent settlements (if a settlement has no listings the webpage loads with all the listings in Hungary)\n",
    "    '''\n",
    "        \n",
    "    headers = ({'User-Agent':\n",
    "            'Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/41.0.2228.0 Safari/537.36'})\n",
    "    \n",
    "    all_obs = int(re.findall(r'\\d+', BeautifulSoup(\n",
    "        get(\"URL to get the number of pages\", headers=headers).text, \n",
    "        'html.parser').find_all('div', class_=\"results__number\")[0].text.replace(' ', ''))[0])\n",
    "    \n",
    "    #classes = ['price', 'price--sqm', 'listing__address', 'listing__data--area-size']\n",
    "    \n",
    "    a = 0\n",
    "    i = 0\n",
    "    \n",
    "    for city in city_list:\n",
    "        \n",
    "        link = url_fix + city\n",
    "        obs = int(re.findall(r'\\d+', BeautifulSoup(\n",
    "            get(link, headers=headers).text, \n",
    "            'html.parser').find_all('div', class_=\"results__number\")[0].text.replace(' ', ''))[0])\n",
    "        \n",
    "        try:\n",
    "        \n",
    "            pages = list(range(1, int(re.findall(\n",
    "                r'\\d+', BeautifulSoup(get(link, headers=headers).text, 'html.parser').find_all(\n",
    "                    'div', class_=\"pagination__page-number\")[0].text)[1])+1))\n",
    "        \n",
    "        except IndexError:\n",
    "            \n",
    "            pages = [1]\n",
    "        \n",
    "        if (obs < all_obs):\n",
    "        \n",
    "            for page in pages:\n",
    "\n",
    "                url = url_fix + city + '?page=' + str(page)\n",
    "                response = get(url, headers=headers)\n",
    "                html_soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "                if len(html_soup.find_all('div', class_=\"listing__address\")) > 0:\n",
    "\n",
    "                    for obs in range(len(html_soup.find_all('div', class_=\"listing__address\"))):\n",
    "\n",
    "                        #info_list = []\n",
    "                        \n",
    "                        #Av. (scrapable) variables\n",
    "                        house_price = html_soup.find_all('div', class_=\"price\")[obs].text\n",
    "                        house_price_sqm = html_soup.find_all('div', class_=\"price--sqm\")[obs].text\n",
    "                        house_address = html_soup.find_all('div', class_=\"listing__address\")[obs].text\n",
    "                        house_sqm = html_soup.find_all('div', class_=\"listing__data--area-size\")[obs].text\n",
    "                        house_rooms =  html_soup.find_all('div', class_=\"listing__data--room-count\")[obs].text\n",
    "\n",
    "                        url = html_soup.find_all('a', class_=\"listing__link js-listing-active-area\")[obs].get('href')\n",
    "                        url = \"Webpage URL\" + url\n",
    "\n",
    "                        settlement = city\n",
    "\n",
    "                        info_list = [house_price, house_price_sqm, house_sqm, house_address, house_rooms, settlement, url]\n",
    "\n",
    "                        info_series = pd.Series(info_list, \n",
    "                                                index = ['ár (M Ft)', 'nm ár', 'méret', 'cím', 'szobák száma', 'település', 'hirdetés link'])\n",
    "                        FlatDataAll = FlatDataAll.append(info_series, ignore_index=True)\n",
    "\n",
    "                else:\n",
    "\n",
    "                    break\n",
    "\n",
    "\n",
    "                i += 1\n",
    "\n",
    "                #print(str(i) + ' pages are done')\n",
    "\n",
    "                t.sleep(random.uniform(1,4))\n",
    "        \n",
    "        \n",
    "            a+=1\n",
    "            print(str(a) + ' cities are done')\n",
    "            \n",
    "        else:\n",
    "            continue\n",
    "    #Gen int from string vars\n",
    "    FlatDataAll['ár (M Ft)'] = FlatDataAll['ár (M Ft)'].str.replace(' M Ft', '').astype(float)\n",
    "    FlatDataAll['nm ár'] = FlatDataAll['nm ár'].str.replace(' ', '')\n",
    "    FlatDataAll['nm ár'] = FlatDataAll['nm ár'].str.replace('Ft/m2', '').astype(int)\n",
    "    FlatDataAll['méret'] = FlatDataAll['méret'].str.extract('(\\d+)')\n",
    "    FlatDataAll['telek méret'] = 0\n",
    "    FlatDataAll['típus'] = 'Lakás' \n",
    "    FlatDataAll['Adatszerzés dátuma'] = str(date.today()) \n",
    "    \n",
    "    return FlatDataAll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_list = list_of_cities  ## All cities and settlements \n",
    "flats_data = flat_prices(city_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### House database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def house_prices(city_list):\n",
    "    \n",
    "    HouseDataAll = pd.DataFrame(columns = ['ár (M Ft)', 'nm ár', 'méret', 'telek méret', 'cím', 'szobák száma', 'település', 'hirdetés link'])\n",
    "    \n",
    "    pages = list(range(1,2))\n",
    "    url_fix = \"Fix part of the URL\"\n",
    "    \n",
    "    '''\n",
    "    all_obs: contains the number of total flat listings in Hungary, this is neccesary to troubleshoot against\n",
    "    non-existent settlements (if a settlement has no listings a webpage loads with all the listings in Hungary)\n",
    "    '''\n",
    "        \n",
    "    headers = ({'User-Agent':\n",
    "            'Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/41.0.2228.0 Safari/537.36'})\n",
    "    \n",
    "    all_obs = int(re.findall(r'\\d+', BeautifulSoup(\n",
    "        get(\"URL to get the number of pages\", headers=headers).text, \n",
    "        'html.parser').find_all('div', class_=\"results__number\")[0].text.replace(' ', ''))[0])\n",
    "    \n",
    "    #classes = ['price', 'price--sqm', 'listing__address', 'listing__data--area-size']\n",
    "    a = 0\n",
    "    i = 0\n",
    "    \n",
    "    for city in city_list:\n",
    "        \n",
    "        link = url_fix + city\n",
    "        obs = int(re.findall(r'\\d+', BeautifulSoup(\n",
    "            get(link, headers=headers).text, \n",
    "            'html.parser').find_all('div', class_=\"results__number\")[0].text.replace(' ', ''))[0])\n",
    "        \n",
    "        try:\n",
    "        \n",
    "            pages = list(range(1, int(re.findall(\n",
    "                r'\\d+', BeautifulSoup(get(link, headers=headers).text, 'html.parser').find_all(\n",
    "                    'div', class_=\"pagination__page-number\")[0].text)[1])+1))\n",
    "        \n",
    "        except IndexError:\n",
    "            \n",
    "            pages = [1]\n",
    "            \n",
    "        if (obs < all_obs):\n",
    "        \n",
    "            for page in pages:\n",
    "\n",
    "                url = url_fix + city + '?page=' + str(page)\n",
    "                response = get(url, headers=headers)\n",
    "                html_soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "                if len(html_soup.find_all('div', class_=\"listing__address\")) > 0:\n",
    "\n",
    "                    for obs in range(len(html_soup.find_all('div', class_=\"listing__address\"))):\n",
    "\n",
    "                        #info_list = []\n",
    "\n",
    "                        house_price = html_soup.find_all('div', class_=\"price\")[obs].text\n",
    "                        house_price_sqm = html_soup.find_all('div', class_=\"price--sqm\")[obs].text\n",
    "                        house_address = html_soup.find_all('div', class_=\"listing__address\")[obs].text\n",
    "                        house_sqm = html_soup.find_all('div', class_=\"listing__data--area-size\")[obs].text\n",
    "                        house_plot_size = html_soup.find_all('div', class_=\"listing__data--plot-size\")[obs].text\n",
    "                        house_rooms =  html_soup.find_all('div', class_=\"listing__data--room-count\")[obs].text\n",
    "                        \n",
    "                        url = html_soup.find_all('a', class_=\"listing__link js-listing-active-area\")[obs].get('href')\n",
    "                        url = \"Webpage URL\" + url\n",
    "\n",
    "                        settlement = city\n",
    "\n",
    "                        info_list = [house_price, house_price_sqm, house_sqm, house_plot_size, house_address, house_rooms, settlement, url]\n",
    "\n",
    "                        info_series = pd.Series(\n",
    "                            info_list, index = ['ár (M Ft)', 'nm ár', 'méret', 'telek méret', 'cím', 'szobák száma', 'település', 'hirdetés link'])\n",
    "\n",
    "                        HouseDataAll = HouseDataAll.append(info_series, ignore_index=True)\n",
    "\n",
    "                else:\n",
    "\n",
    "                    break\n",
    "\n",
    "                i += 1\n",
    "                print(str(i) + ' pages are done')\n",
    "                t.sleep(random.uniform(4, 10))\n",
    "\n",
    "\n",
    "            a+=1\n",
    "            print(str(a) + ' cities are done')\n",
    "        \n",
    "        else:\n",
    "            continue\n",
    "\n",
    "    HouseDataAll['ár (M Ft)'] = HouseDataAll['ár (M Ft)'].str.replace(' M Ft', '').astype(float)\n",
    "    HouseDataAll['nm ár'] = HouseDataAll['nm ár'].str.replace(' ', '')\n",
    "    HouseDataAll['nm ár'] = HouseDataAll['nm ár'].str.replace('Ft/m2', '').astype(int)\n",
    "    HouseDataAll['méret'] = HouseDataAll['méret'].str.extract('(\\d+)')\n",
    "    HouseDataAll['telek méret'] = HouseDataAll['telek méret'].str.replace(' ', '')\n",
    "    HouseDataAll['telek méret'] = HouseDataAll['telek méret'].str.extract('(\\d+)')\n",
    "    HouseDataAll['típus'] = 'Ház' \n",
    "    HouseDataAll['Adatszerzés dátuma'] = str(date.today())\n",
    "    \n",
    "    return HouseDataAll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_list = list_of_cities  ## All cities and settlements \n",
    "houses_data = house_prices(city_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataAll = houses_data.append(flats_data,ignore_index = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
